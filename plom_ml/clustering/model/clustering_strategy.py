# SPDX-License-Identifier: AGPL-3.0-or-later
# Copyright (C) 2025 Bryan Tanady

# sklearn
from sklearn.metrics import silhouette_score, davies_bouldin_score
from sklearn.decomposition import PCA
from sklearn.cluster import AgglomerativeClustering


# plom_ml
from plom_ml.clustering.embedding.embedder import (
    Embedder,
    SymbolicEmbedder,
    TrOCREmbedder,
    MCQEmbedder,
)
from plom_ml.clustering.exceptions import MissingEmbedderException

# torch
import torch

# misc
from abc import abstractmethod
import numpy as np
import yaml
import os
from typing import Mapping


class ClusteringStrategy:
    """Abstract base class for clustering strategy.

    A clustering strategy defines:
        a. Embedders used to generate features for PREPROCESSED inputs
        b. clustering algorithm used to cluster the generated features.
        c. Any task-specific logic eg: PCA decomposition before clustering

    This class enforces every subclass to implement cluster_papers that outputs the
    paper_number to their clusterId. Furthermore the class has get_embeddings method
    that generate a feature vector for an image. The feature vector is a concatenation of
    embeddings generated by the embedderes.
    """

    embedders: list[Embedder]

    def get_embeddings(self, image: np.ndarray) -> np.ndarray:
        """Generate an array of embeddings generated by embedders for the inputted image.

        Args:
            image: the image whose feature vector will be generated for clustering.

        Returns:
            a 1D array of feature vector with shape of shape (D,). D is the sum of output
            dimensions from all embedders.

        Raises:
            MissingEmbedderException: if ClusteringStrategy has not initialized embedders property.
        """
        if not hasattr(self, "embedders") or not self.embedders:
            raise MissingEmbedderException(
                f"Missing self.embedders in {self.__class__.__name__} ClusteringStrategy"
            )

        return np.concatenate([embedder.embed(image) for embedder in self.embedders])

    @abstractmethod
    def cluster_papers(
        self, paper_to_image: Mapping[int, np.ndarray]
    ) -> dict[int, int]:
        """Cluster the given papers into a mapping of paper_num to clusterId.

        This method directly calls inference models on the provided images. Therefore, if
        there are expected preprocessing steps, the images must be preprocessed before
        feeding them into this function.

        Args:
            paper_to_image: a dictionary mapping paper number to a (processed) image that
            represents that paper.

        Returns:
            A dictionary mapping the paper number to their cluster id.
        """
        pass


class HMEClusteringStrategy(ClusteringStrategy):
    """Handwritten math expression model."""

    def __init__(self):
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # load model config
        config_path = os.path.join(os.path.dirname(__file__), "model_config.yaml")
        with open(config_path) as f:
            config = yaml.safe_load(f)

        # load weights path
        symbolic_model_path = config["models"]["hme"]["symbolic"]
        trocr_model_path = config["models"]["hme"]["trocr"]

        # Init embedders
        self.embedders = [
            SymbolicEmbedder(symbolic_model_path, device),
            TrOCREmbedder(trocr_model_path, device),
        ]

    def get_best_clustering(
        self, X: np.ndarray, thresholds: list[float], metric="silhouette"
    ) -> np.ndarray:
        """Get the best clustering of X by searching for optimal threshold that maximizes the metric.

        This function defaults with AgglomerativeClustering clustering algorithm.

        Args:
            X: the feature matrix.
            thresholds: the choices of distance thresholds.
            metric: which metric to optimize. Currently supports: "silhouette" and "davies".

        Returns:
            A numpy array of clusterId where the order matches with the
            inputs (index 0 provides Id for row 0 of X)
        """
        best_score = -np.inf if metric == "silhouette" else np.inf
        best_labels = np.array([])

        for t in thresholds:
            clustering = AgglomerativeClustering(
                n_clusters=None, metric="euclidean", distance_threshold=t
            )
            labels = clustering.fit_predict(X)
            # need at least 2 clusters to score
            if len(set(labels)) < 2:
                continue

            if metric == "silhouette":
                score = silhouette_score(X, labels)
                # silhouette: higher -> better
                if score > best_score:
                    best_score = score
                    best_labels = labels

            elif metric == "davies":
                score = davies_bouldin_score(X, labels)
                # DB index: lower -> better
                if score < best_score:
                    best_score = score
                    best_labels = labels

        return best_labels

    def cluster_papers(
        self, paper_to_image: Mapping[int, np.ndarray]
    ) -> dict[int, int]:
        """Cluster the given papers.

        Args:
            paper_to_image: a dictionary mapping paper number to a (processed) image.

        Returns:
            A dictionary mapping the paper number to their cluster id.
        """
        # Build feature matrix
        X = np.vstack(
            [self.get_embeddings(image) for pn, image in paper_to_image.items()]
        )

        X_reduced = PCA(n_components=min(len(paper_to_image), 50)).fit_transform(X)

        # set up distance threshold search space
        min_thresh = 4
        max_thresh = 10
        thresh_counts = 100
        thresholds = [
            float(t) for t in np.linspace(min_thresh, max_thresh, thresh_counts)
        ]

        clusterIDs = self.get_best_clustering(X_reduced, thresholds, "davies")
        return dict(zip(list(paper_to_image.keys()), clusterIDs))


class MCQClusteringStrategy(ClusteringStrategy):
    """Handwritten MCQ clustering model."""

    def __init__(self):
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # load model config
        config_path = os.path.join(os.path.dirname(__file__), "model_config.yaml")
        with open(config_path) as f:
            config = yaml.safe_load(f)

        # load weight path
        weight_path = config["models"]["mcq"]

        # init embedder
        out_features = 11
        self.embedders = [
            MCQEmbedder(
                weight_path=weight_path, device=device, out_features=out_features
            )
        ]

    def cluster_papers(
        self, paper_to_image: Mapping[int, np.ndarray]
    ) -> dict[int, int]:
        """Cluster papers based on handwritten MCQ.

        Args:
            paper_to_image: a dictionary mapping paper number to the
                cropped region used for clustering.

        Returns:
            A dictionary mapping the paper number to their cluster id
        """
        # Build feature matrix
        X = np.vstack(
            [self.get_embeddings(image) for _, image in paper_to_image.items()]
        )

        # cluster on that matrix
        clustering_model = AgglomerativeClustering(
            n_clusters=None, distance_threshold=1.0, linkage="ward"
        )

        clusterIDs = clustering_model.fit_predict(X)
        return dict(zip(list(paper_to_image.keys()), clusterIDs))
